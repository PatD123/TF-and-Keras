{"cells":[{"cell_type":"markdown","metadata":{"id":"vipXgLmqzHwr"},"source":["# Keys"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1628262400269,"user":{"displayName":"labesh baral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgKfkRAcC4q8O4AOIGKbBTAqtxCx15FOR_A-b0=s64","userId":"09665838403334475686"},"user_tz":240},"id":"MdW0W93YnF-W"},"outputs":[],"source":["# Read API secrets from twitter_secrets.cfg\n","\n","from configparser import ConfigParser\n","parser = ConfigParser()\n","_ = parser.read(\"twitter_secrets.cfg\")\n","\n","ACCESS_TOKEN = parser.get(\"twitter\", \"access_token\")\n","ACCESS_TOKEN_SECRET = parser.get(\"twitter\", \"access_token_secret\")\n","CONSUMER_KEY = parser.get(\"twitter\", \"consumer_key\")\n","CONSUMER_SECRET = parser.get(\"twitter\", \"consumer_secret\")"]},{"cell_type":"markdown","metadata":{"id":"ah_KTX-dzJ89"},"source":["# Import Stuffs"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3922,"status":"ok","timestamp":1628262381444,"user":{"displayName":"labesh baral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgKfkRAcC4q8O4AOIGKbBTAqtxCx15FOR_A-b0=s64","userId":"09665838403334475686"},"user_tz":240},"id":"P6jcjT4M0_fT","outputId":"87832447-dc78-49d8-9d08-9cc1e947844f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 926 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pytorch_pretrained_bert) (2.25.1)\n","Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pytorch_pretrained_bert) (1.19.5)\n","Collecting torch>=0.4.1\n","  Downloading torch-1.10.0-cp38-none-macosx_10_9_x86_64.whl (147.1 MB)\n","\u001b[K     |████████████████████████████████| 147.1 MB 26 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n","Collecting boto3\n","  Downloading boto3-1.19.12-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 12.5 MB/s \n","\u001b[?25hCollecting botocore<1.23.0,>=1.22.12\n","  Downloading botocore-1.22.12-py3-none-any.whl (8.1 MB)\n","\u001b[K     |████████████████████████████████| 8.1 MB 20.7 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from botocore<1.23.0,>=1.22.12->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from botocore<1.23.0,>=1.22.12->boto3->pytorch_pretrained_bert) (1.25.10)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.12->boto3->pytorch_pretrained_bert) (1.15.0)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.2 MB/s \n","\u001b[?25hCollecting regex\n","  Downloading regex-2021.11.2-cp38-cp38-macosx_10_9_x86_64.whl (288 kB)\n","\u001b[K     |████████████████████████████████| 288 kB 15.1 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /Users/louismeunier/Library/Python/3.8/lib/python/site-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /Users/louismeunier/Library/Python/3.8/lib/python/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Collecting tqdm\n","  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 5.4 MB/s \n","\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, tqdm, torch, regex, boto3, pytorch-pretrained-bert\n","Successfully installed boto3-1.19.12 botocore-1.22.12 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 regex-2021.11.2 s3transfer-0.5.0 torch-1.10.0 tqdm-4.62.3\n","\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n","You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n","\u001b[31mERROR: Could not find a version that satisfies the requirement bertModel\u001b[0m\n","\u001b[31mERROR: No matching distribution found for bertModel\u001b[0m\n","\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n","You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install pytorch_pretrained_bert\n","!pip install bertModel "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":396,"status":"ok","timestamp":1628262402053,"user":{"displayName":"labesh baral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgKfkRAcC4q8O4AOIGKbBTAqtxCx15FOR_A-b0=s64","userId":"09665838403334475686"},"user_tz":240},"id":"7n8akrq3zLW3"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tweepy'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/var/folders/ms/5v3xr1md4jg_ghk8ygp_cscc0000gn/T/ipykernel_49192/1087533222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamListener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOAuthHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"]}],"source":["from tweepy.streaming import StreamListener\n","from tweepy import API, Cursor, Stream, OAuthHandler\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","from textblob import TextBlob\n","import re\n","import datetime\n","from nltk.tokenize import WordPunctTokenizer\n","from bs4 import BeautifulSoup\n","tok = WordPunctTokenizer()\n","pat1 = r'@[A-Za-z0-9]+'\n","pat2 = r'https?://[A-Za-z0-9./]+'\n","combined_pat = r'|'.join((pat1, pat2))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":4,"status":"error","timestamp":1628262402053,"user":{"displayName":"labesh baral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgKfkRAcC4q8O4AOIGKbBTAqtxCx15FOR_A-b0=s64","userId":"09665838403334475686"},"user_tz":240},"id":"rWMoqEt8sTLH","outputId":"f2d5c6c1-445d-40af-f0c5-1d51aebd3cc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-054aaad160a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_pretrained_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertModel'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import torch\n","import torch.nn.functional as F\n","from pytorch_pretrained_bert import BertTokenizer\n","from bertModel import BertClassification"]},{"cell_type":"markdown","metadata":{"id":"MKMHUaRKC0uH"},"source":["# Pre-trained FinBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3bSxI-2BBV9"},"outputs":[],"source":["labels = {0:'neutral', 1:'positive',2:'negative'}\n","num_labels= len(labels)\n","vocab = \"finance-uncased\"\n","vocab_path = '/content/drive/MyDrive/analyst_tone/vocab'\n","pretrained_weights_path = \"/content/drive/MyDrive/analyst_tone/pretrained_weights\" # this is pre-trained FinBERT weights\n","fine_tuned_weight_path = \"/content/drive/MyDrive/analyst_tone/fine_tuned.pth\"      # this is fine-tuned FinBERT weights\n","max_seq_length=512\n","device='cuda:0'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFhGwV-_BEcq"},"outputs":[],"source":["model = BertClassification(weight_path= pretrained_weights_path, num_labels=num_labels, vocab=vocab)\n","model.load_state_dict(torch.load(fine_tuned_weight_path, 'cuda:0'))\n","model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lngwHCcB87e"},"outputs":[],"source":["sentences = [\"There is a shortage of capital, and we need extra financing\", \n","             \"Growth is strong and we have plenty of liquidity.\", \n","             \"There are doubts about our finances.\", \n","             \"Facebook is going down bad.\"]\n","tokenizer = BertTokenizer(vocab_file = vocab_path, do_lower_case = True, do_basic_tokenize = True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"153LtB5-CBgS"},"outputs":[],"source":["def sa(sent):\n","  tokenized_sent = tokenizer.tokenize(sent)\n","  if len(tokenized_sent) > max_seq_length:\n","      tokenized_sent = tokenized_sent[:max_seq_length]\n","    \n","  ids_review  = tokenizer.convert_tokens_to_ids(tokenized_sent)\n","  mask_input = [1]*len(ids_review)        \n","  padding = [0] * (max_seq_length - len(ids_review))\n","  ids_review += padding\n","  mask_input += padding\n","  input_type = [0]*max_seq_length\n","    \n","  input_ids = torch.tensor(ids_review).to(device).reshape(-1, max_seq_length)\n","  attention_mask =  torch.tensor(mask_input).to(device).reshape(-1, max_seq_length)\n","  token_type_ids = torch.tensor(input_type).to(device).reshape(-1, max_seq_length)\n","    \n","  with torch.set_grad_enabled(False):\n","      outputs = model(input_ids, token_type_ids, attention_mask)\n","      outputs = F.softmax(outputs,dim=1)\n","      return labels[torch.argmax(outputs).item()]\n","      #print(sent, '\\nFinBERT predicted sentiment: ', outputs, '\\n')\n","      #neutral, pos, neg"]},{"cell_type":"markdown","metadata":{"id":"swp-bJL_0LEl"},"source":["# Classes"]},{"cell_type":"markdown","metadata":{"id":"0K4H4uPsOLLF"},"source":["## TwitterAuthenticator Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_N8TvxmOOf3"},"outputs":[],"source":["class TwitterAuthenticator():\n","  def authenticate_twitter_app(self):\n","    auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n","    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n","    return auth"]},{"cell_type":"markdown","metadata":{"id":"3lI5beofOXHb"},"source":["## TwitterListener Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ji3v-VSn0MOk"},"outputs":[],"source":["class TwitterListener(StreamListener): # Inherits from StreamListener Class\n","  '''\n","  Simple listener class that just prints received tweets to standard output.\n","  '''\n","  \n","  def __init__(self, fetched_tweets_filename):\n","    self.fetched_tweets_filename = fetched_tweets_filename \n","\n","  def on_data(self, data):\n","    try:\n","      print(data)\n","      with open(self.fetched_tweets_filename, 'a') as tf:\n","        tf.write(data)\n","      return True\n","    except BaseException as e:\n","      print(\"Error on_data %s\" % str(e))\n","    return true\n","\n","  def on_error(self, status):\n","    if status == 420:\n","      # Case rate limit occurs\n","      return False;\n","    print(status)"]},{"cell_type":"markdown","metadata":{"id":"D7cAdyXifcOR"},"source":["## TweetAnalyzer Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yWNXowAffaE"},"outputs":[],"source":["class TweetAnalyzer():\n","  def tweets_to_df(self, tweets):\n","    df = pd.DataFrame(data=[tweet.full_text for tweet in tweets], columns=[\"tweets\"])\n","    df['id'] = np.array([tweet.id for tweet in tweets])\n","    df['len'] = np.array([len(tweet.full_text) for tweet in tweets])\n","    df['date'] = np.array([tweet.created_at for tweet in tweets])\n","    df['source'] = np.array([tweet.source for tweet in tweets])\n","    df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n","    df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n","    return df\n","\n","  def relating(self, t):\n","    df2 = t['id']\n","    df2['tweets'] = np.array(t['text'])\n","    df2['date'] = np.array(t['created_at'])\n","    df2['source'] = np.array(t['source'])\n","    df2['likes'] = np.array(t['favorite_count'])\n","    df2['retweets'] = np.array(t['retweet_count'])\n","    return df2\n","\n","  def clean_tweet(self, text):\n","    text = re.sub('\\\\n', '', text)\n","    text = re.sub('https?:\\/\\/\\S+', u'', text)\n","    text = re.sub('\\xa0', u'', text)\n","    soup = BeautifulSoup(text, 'lxml')\n","    souped = soup.get_text()\n","    stripped = re.sub(combined_pat, '', souped)\n","    try:\n","        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n","    except:\n","        clean = stripped\n","    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n","    lower_case = letters_only.lower()\n","    # During the letters_only process two lines above, it has created unnecessay white spaces,\n","    # I will tokenize and join together to remove unneccessary white spaces\n","    words = tok.tokenize(lower_case)\n","    return (\" \".join(words)).strip()\n","\n","  def analyze_sentiment(self, tweet):\n","    #analysis = TextBlob(self.clean_tweet(tweet))\n","    #return analysis.sentiment.polarity\n","    twt = self.clean_tweet(tweet)\n","    return sa(twt)\n","    "]},{"cell_type":"markdown","metadata":{"id":"Z_42f65GOF66"},"source":["## TwitterClient Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHCFcmpcOIgn"},"outputs":[],"source":["class TwitterClient():\n","  def __init__(self, twitter_user=None): # When you do the None, it means default. If no user is specified, it defaults to you.\n","    self.auth = TwitterAuthenticator().authenticate_twitter_app()\n","    self.twitter_client = API(self.auth)\n","    \n","    self.twitter_user = twitter_user\n","  \n","  def get_user_timeline_tweets(self, num_tweets):\n","    tweets = []\n","    search_term = '$INTC AND (buy OR sell) AND Intel -filter:retweets'\n","    for tweet in Cursor(api.search, q=search_term, lang = 'en', since = '2021-07-28', tweet_mode='extended').items(num_tweets): # The API provides a timeline for every user, which gets the tweets from a user.\n","      tweets.append(tweet)\n","    return tweets\n","\n","  def get_home_timeline_tweets(self, num_tweets):\n","        home_timeline_tweets = []\n","        for tweet in Cursor(self.twitter_client.home_timeline, id=self.twitter_user).items(num_tweets):\n","            home_timeline_tweets.append(tweet)\n","        return home_timeline_tweets\n","\n","  def get_twitter_client_api(self):\n","    return self.twitter_client"]},{"cell_type":"markdown","metadata":{"id":"p9Sqmv4DOPBD"},"source":["## TwitterStreamer Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obvIDKbjOVfL"},"outputs":[],"source":["class TwitterStreamer():\n","  '''\n","  Class for streaming and processing live tweets\n","  '''\n","\n","  def __init__(self):\n","    self.twitter_authenticator = TwitterAuthenticator()\n","\n","  def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n","    # Handles Twitter Auth and connects to the Twitter Streaming API.\n","    listener = TwitterListener(fetched_tweets_filename)\n","    auth = self.twitter_authenticator.authenticate_twitter_app()\n","    \n","    stream = Stream(auth, listener)\n","    # stream.filter(track=['donald trump', 'hillary clinton', 'bernie sanders', 'barack obama'])\n","    stream.filter(track=hash_tag_list)"]},{"cell_type":"markdown","metadata":{"id":"4uwViHSrOfj4"},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOeCR9RbOgko"},"outputs":[],"source":["if __name__ == \"__main__\":\n","  #twitter_client = TwitterClient('TheRealPatD123') # Put person here.\n","  #print(twitter_client.get_user_timeline_tweets(2)) # Can get number of pages of tweets for people, not just the number of tweets\n","\n","  # Getting Tweets from a specific person and doing SA on it.\n","  twitter_client = TwitterClient()\n","  api = twitter_client.get_twitter_client_api()\n","\n","  #tweets = api.user_timeline(screen_name='HillaryClinton', count=2)\n","  tweets = twitter_client.get_user_timeline_tweets(200)\n","  tweet_analyzer = TweetAnalyzer()\n","  df = tweet_analyzer.tweets_to_df(tweets)\n","  \n","  # print(tweets[0].favorite_count)\n","\n","  #TIME SERIES\n","  #time_likes = pd.Series(df['likes'].values, index=df['date'])\n","  #time_likes.plot(figsize=(16, 4), label='likes', legend=True)\n","  #time_retweets = pd.Series(df['retweets'].values, index=df['date'])\n","  #time_retweets.plot(figsize=(16, 4), label='retweets', legend=True)\n","  #plt.show()\n","  \n","  # Sentiment Analysis\n","  df['sentiment'] = [tweet_analyzer.analyze_sentiment(tweet.full_text) for tweet in tweets]\n","  # df['clean_tweets'] = [tweet_analyzer.clean_tweet(df.iloc[i]['tweets']) for i in range(0, df.shape[0])]\n","  print(df)\n","\n","  # Filtering for certain tweets\n","  #hash_tag_list = ['donald trump']\n","  #fetched_tweets_filename = \"tweets.json\"\n","  #twitter_streamer = TwitterStreamer()\n","  #twitter_streamer.stream_tweets(fetched_tweets_filename, hash_tag_list)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2rmrWzWk9nWR"},"outputs":[],"source":["from statistics import median\n","\n","df['date'] = matplotlib.dates.date2num(df['date'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkHjojsEu-RB"},"outputs":[],"source":["for i in range(0, df.shape[0]):\n","  print(df.iloc[i]['sentiment'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iLOJh0XwW78"},"outputs":[],"source":["for i in range(df.shape[0] - 1, -1, -1):\n","  #df.iloc[i]['date'] = round(df.iloc[i]['date'], 3)\n","  if df.iloc[i]['sentiment'] == 0:\n","    df = df.drop(i, 0)\n","\n","df = df.sort_values(by =['date'])\n","\n","l = []\n","for i in range(0, df.shape[0] - 1):\n","  l.append(df.iloc[i]['sentiment'])\n","\n","  if df.iloc[i]['date'] != df.iloc[i + 1]['date']:\n","    df.iloc[i]['sentiment'] = median(l)\n","    l.clear()\n","  else:\n","    df = df.drop(i, 0)\n","\n","\n","\n","plt.plot_date(df['date'], df['sentiment'])\n","plt.gcf().autofmt_xdate()\n","# plt.xticks(ticks=np.arange(datetime(2021, 7,27), datetime(2021, 8,3), timedelta(days = 2)))\n","plt.minorticks_on();\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7_LNKZpwQt-"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYhU6_cJlM8k"},"outputs":[],"source":["for i in range (0, df.shape[0]):\n","  print(i)\n","  print(df.iloc[i]['tweets'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jCj-O1p-IRz"},"outputs":[],"source":["#g = pd.read_json('tweets.json', lines=True)\n","#h = relating(g)\n","#print(h)\n","#h['sentiment'] = [tweet_analyzer.analyze_sentiment(g.iloc[i]['text']) for i in range(0, g.shape[0])]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_MP0gEEEl18n"},"outputs":[],"source":["print(dir(tweets[0])) # Shows the number of options you can access from one tweet(user, text, place, retweet count, etc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mbGUfSCkbCP"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"TwitterSA.ipynb","provenance":[]},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"},"kernelspec":{"display_name":"Python 3.8.3 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}

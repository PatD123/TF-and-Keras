{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"(15, 348).ipynb","provenance":[],"authorship_tag":"ABX9TyOD5eiXsLdx+WXeSYnn7MC3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yc-JmlujMS__"},"source":["# Import stuffs"]},{"cell_type":"code","metadata":{"id":"47ar8TccMOTz"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorboard\n","import datetime\n","from sklearn.model_selection import train_test_split\n","\n","def generate_time_series(batch_size, n_steps):\n","    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n","    time = np.linspace(0, 1, n_steps)\n","    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1\n","    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n","    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise\n","    return series[..., np.newaxis].astype(np.float32)\n","\n","n_steps = 50\n","series = generate_time_series(10000, n_steps + 1)\n","x_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n","x_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n","x_test, y_test = series[9000:, :n_steps], series[9000:, -1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JUzRjq84E7VM"},"source":["# Creating a baseline model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":680},"id":"qAuU3ZEfE-F7","executionInfo":{"status":"error","timestamp":1625598996344,"user_tz":240,"elapsed":5991,"user":{"displayName":"ThatOneGuy 4","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifdiA3IY1W_lxhJLvpVcINYel5dPvvCji8tMXk=s64","userId":"01730018351539431740"}},"outputId":"82696f5c-f073-4ae6-82f8-e385ec60a964"},"source":["model = keras.Sequential([\n","  keras.layers.Flatten(input_shape=[50, 1]),\n","  keras.layers.Dense(1)                          \n","])\n","\n","model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(), metrics=[\"mse\"])\n","model.fit(x_train, y_train, epochs=100,\n","          validation_data=(x_valid, y_valid))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","219/219 [==============================] - 1s 3ms/step - loss: 0.1035 - mse: 0.1035 - val_loss: 0.0478 - val_mse: 0.0478\n","Epoch 2/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0238 - val_mse: 0.0238\n","Epoch 3/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0144 - val_mse: 0.0144\n","Epoch 4/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0107 - val_mse: 0.0107\n","Epoch 5/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0090 - val_mse: 0.0090\n","Epoch 6/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0079 - val_mse: 0.0079\n","Epoch 7/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0072 - val_mse: 0.0072\n","Epoch 8/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0066 - val_mse: 0.0066\n","Epoch 9/100\n","219/219 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0061 - val_mse: 0.0061\n","Epoch 10/100\n","207/219 [===========================>..] - ETA: 0s - loss: 0.0058 - mse: 0.0058"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ceb266616608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.fit(x_train, y_train, epochs=100,\n\u001b[0;32m----> 8\u001b[0;31m           validation_data=(x_valid, y_valid))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1481\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    716\u001b[0m           gen_dataset_ops.anonymous_iterator_v2(\n\u001b[1;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m               output_shapes=self._flat_output_shapes))\n\u001b[0m\u001b[1;32m    719\u001b[0m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36manonymous_iterator_v2\u001b[0;34m(output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m    124\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m    125\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AnonymousIteratorV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m    127\u001b[0m       \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AnonymousIteratorV2Output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"-Ko9IAIUF0IX"},"source":["# Creating a simple RNN"]},{"cell_type":"code","metadata":{"id":"0TH-NAS-F2Rr"},"source":["model = keras.Sequential([\n","  keras.layers.SimpleRNN(1, input_shape=[None, 1])       # None because the RNN can take any number of time steps                \n","])                                                       # as the input size is rolled out\n","\n","model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(), metrics=[\"mse\"])\n","model.fit(x_train, y_train, epochs=100,\n","          validation_data=(x_valid, y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hfHdWyVTKzMm"},"source":["# Deep RNNs\n","- Just stack em to make em DEEP"]},{"cell_type":"code","metadata":{"id":"f3I3WYM0K2gT"},"source":["model = keras.Sequential([\n","  keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]), #[Time steps, dimensionality]\n","  keras.layers.SimpleRNN(20),\n","  # keras.layers.SimpleRNN(1) ---> Not ideal to have this here as it is just one unit in the RNN, which s useless.\n","  keras.layers.Dense(1) # Converges faster too!\n","])\n","\n","model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(), metrics=[\"mse\"])\n","model.fit(x_train, y_train, epochs=50,\n","          validation_data=(x_valid, y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qti-bMndPCZj"},"source":["## Forecasting multiple steps ahead"]},{"cell_type":"code","metadata":{"id":"pzB9g8cJPaae"},"source":["n_steps = 50\n","series = generate_time_series(10000, n_steps + 10)\n","x_train, y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n","x_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n","x_test, y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4K-e9A7HPFeZ"},"source":["model = keras.Sequential([\n","  keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]), #[batch_size, time steps, dimensionality]\n","  keras.layers.SimpleRNN(20), # keras.layers.SimpleRNN(20, return_sequences=True) **** Can't do this here because YOU ONLY DO RETURN_SEQUENCES\n","                                                                                        # WHEN UR STACKING RNN CELLS. On the previous line, you do true because \n","                                                                                        # this line is still stacking, but the next Dense layer is not a RNN cell\n","                                                                                          # so can't do True.          \n","  # keras.layers.SimpleRNN(1) ---> Not ideal to have this here as it is just one unit in the RNN, which s useless.\n","  keras.layers.Dense(10) # Converges faster too!\n","])\n","\n","model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(), metrics=[\"mse\"])\n","model.fit(x_train, y_train, epochs=20,\n","          validation_data=(x_valid, y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dagJ3qfRbob"},"source":["## Better optimization is to predict the next ten steps at each time step.\n","- At time step=0, it will predict the next 10 time steps(1-10)"]},{"cell_type":"code","metadata":{"id":"WxNLI-DoSUbm"},"source":["Y = np.empty((10000, n_steps, 10))\n","for step_ahead in range(1, 10 + 1):\n","  Y[:, :, step_ahead - 1] = Y[:, step_ahead: step_ahead + n_steps, 0]\n","y_train = Y[:7000]\n","y_valid = Y[7000:9000]\n","y_test = Y[9000:]  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UqpWJKSlU0IG"},"source":["model = keras.Sequential([\n","  keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),  # Use return_sequences when stacking stuff\n","  keras.layers.SimpleRNN(20, return_sequences=True),\n","  keras.layers.TimeDistributed(keras.layers.Dense(10)) # Wraps the Dense so that it applies this Dense at every single Time Step                          \n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3POkInojVtY4","executionInfo":{"status":"ok","timestamp":1625669110187,"user_tz":240,"elapsed":169,"user":{"displayName":"ThatOneGuy 4","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifdiA3IY1W_lxhJLvpVcINYel5dPvvCji8tMXk=s64","userId":"01730018351539431740"}},"outputId":"ae5bba9e-01e4-4f93-e4ac-5982917265af"},"source":["# Our model keeps all the outputs of all the other layers but only the last output is important so we only use that\n","def last_time_step_mse(y_true, y_pred):\n","  return keras.metrics.MeanSquaredError(y_true[:, -1], y_pred[:, -1])\n","\n","optimizer = keras.optimizers.Adam(lr=0.01)\n","model.compile(loss=\"mse\", optimizer=optimizer, metrics=last_time_step_mse)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"02azWWZtWpQC"},"source":["# Building a Custom Simple RNN Cell with Layer Normalization(pg 358)\n","- Never use BN in RNNs. ***Always use Layer Normalization***\n","- There already is a thing in TF called the SimpleRNNCell, but it doesn't have layer Normalization.\n","- Also helps to alleviate exploding gradients"]},{"cell_type":"code","metadata":{"id":"_jk9QRypWxaP"},"source":["class LNSimpleRNNCell(keras.layers.Layer):\n","  def __init__(self, units, activation=\"tanh\", **kwargs): # Use a saturating activation function like tanh(not relu)\n","    super().__init__(**kwargs)\n","    self.state_size = units\n","    self.output_size = units\n","    self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)\n","    self.layer_norm = keras.layers.LayerNormalization()\n","    self.activation = keras.activations.get(activation)\n","  def call(self, inputs, states):\n","    outputs, new_states = self.simple_rnn_cell(inputs, states)\n","    norm_outputs = self.activation(self.layer_norm(outputs))\n","    return norm_outputs, [norm_outputs] # In a simple RNN cell, the output is the same as the hidden state"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gb2CRRiIY9nH"},"source":["model = keras.Sequential([\n","  keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),\n","  keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n","  keras.layers.TimeDistributed(keras.layers.Dense(10))\n","])  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O_w3Vcvpb758"},"source":["# LSTM Cells\n","- Very well explained on pg in picture"]},{"cell_type":"code","metadata":{"id":"sylRPpbrb9QW"},"source":["model = keras.Sequential([\n","  keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n","  keras.layers.LSTM(20, return_sequences=True),\n","  keras.layers.TimeDistributed(keras.layers.Dense(10))\n","])  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wMM1Kk6qf3LT"},"source":["# WaveNet"]},{"cell_type":"code","metadata":{"id":"57cKns9kf5dh"},"source":["model = keras.Sequential()\n","model.add(keras.layers.Input(input_shape=[None, 1]))\n","for rate in (1, 2, 4, 8) * 2:\n","  model.add(keras.layers.Conv1D(filters=20, kernel_size=20, padding=\"causal\",\n","                                activation=\"relu\", dilation_rate=rate))\n","model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vcaK2V7yKINS"},"source":["# RNN Notes\n","- https://towardsdatascience.com/all-you-need-to-know-about-rnns-e514f0b00c7c\n","- ***OFTEN GOOD TO HAVE MC DROPOUT, SO PUT THEM IN EACH MEMORY CELL***\n","- Normally, tf returns one output from the whole entire recurrent layer. To get it to be something like sequence-to-sequence, you have to do return_sequences and have to use TimeDistributed so that each time step can produce and output(seqeunce-to-sequence)"]}]}